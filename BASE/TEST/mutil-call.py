import httpx
import pandas as pd
import json
import time
from pathlib import Path
from BASE.config import *
from BASE.LIB.common import logger

def batch_get_receipts_with_progress(
    input_file: str,
    rpc_url: str,
    limit: int = 10,
    output_file: str = "batch_receipts_result.json"
):
    # === 1ï¸âƒ£ åŠ è½½æ•°æ® ===
    ext = Path(input_file).suffix.lower()
    if ext == ".csv":
        df = pd.read_csv(input_file)
    elif ext in [".xls", ".xlsx"]:
        df = pd.read_excel(input_file)
    else:
        logger.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
        return

    if "hash" not in df.columns:
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ° 'hash' åˆ—ï¼è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
        return

    tx_hashes = df["hash"].dropna().astype(str).head(limit).tolist()
    if not tx_hashes:
        logger.error(f"âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„äº¤æ˜“å“ˆå¸Œã€‚")
        return

    logger.info(f"âœ… è¯»å–åˆ° {len(tx_hashes)} æ¡äº¤æ˜“å“ˆå¸Œï¼Œå°†æ‰¹é‡æŸ¥è¯¢ã€‚")

    # === 2ï¸âƒ£ æ„é€ æ‰¹é‡è¯·æ±‚ ===
    payload = [
        {
            "jsonrpc": "2.0",
            "id": i,
            "method": "eth_getTransactionReceipt",
            "params": [tx_hash]
        }
        for i, tx_hash in enumerate(tx_hashes)
    ]

    # === 3ï¸âƒ£ å‘è¯·æ±‚å¹¶æµå¼è§‚æµ‹ ===
    try:
        logger.info(f"ğŸš€ æ­£åœ¨å‘é€æ‰¹é‡è¯·æ±‚ï¼Œå…± {len(payload)} ä¸ªäº¤æ˜“æ”¶æ® ...")
        with httpx.stream("POST", rpc_url, json=payload, timeout=30.0) as response:
            logger.info(f"âœ… è¯·æ±‚å·²å‘é€ï¼ŒçŠ¶æ€ç : {response.status_code}")
            chunks = []
            for chunk in response.iter_bytes():
                logger.info(f"ğŸ“¦ æ”¶åˆ° {len(chunk)} å­—èŠ‚æ•°æ®")
                chunks.append(chunk)

            body = b"".join(chunks)

        # è§£æ JSON
        try:
            results = json.loads(body.decode("utf-8"))
        except Exception as e:
            logger.error(f"âŒ å“åº”è§£æå¤±è´¥: {e}")
            return

        # ä¿å­˜æ–‡ä»¶
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… å·²å°†è¿”å›æ•°æ®ä¿å­˜è‡³ {output_file}")

        logger.info(f"ğŸ“Œ è¿”å›äº† {len(results)} æ¡ç»“æœã€‚")
        for item in results[:3]:  # æ‰“å°å‰ 3 æ¡
            txid = item.get("id")
            receipt = item.get("result")
            if receipt:
                logger.info(f"ğŸŸ¢ txid={txid}, blockNumber={receipt.get('blockNumber')}, status={receipt.get('status')}")
            else:
                logger.warning(f"âš ï¸  txid={txid}ï¼Œæœªæ‰¾åˆ°æ”¶æ®")

    except Exception as e:
        logger.error(f"âŒ è¯·æ±‚å‡ºé”™: {e}")
        return

# ========== ç¤ºä¾‹è°ƒç”¨ ==========
if __name__ == "__main__":
    start = time.time()

    batch_get_receipts_with_progress(
        input_file=DATA + "aribi_transaction.csv",
        rpc_url=BASE_RPC_URL,
        limit=10,  # ä½ å¯ä»¥æ‰‹åŠ¨æ”¹è¿™ä¸ªæ•°æµ‹æœ€ä½³ batch
        output_file=DATA + "batch_receipts_result.json"
    )

    duration = time.time() - start
    logger.info(f"â± æ€»è€—æ—¶: {duration:.2f} ç§’")
